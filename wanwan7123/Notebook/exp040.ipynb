{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1655457989020,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"k3QT3hl827yR","outputId":"ce5902e5-c691-47b8-d88f-4df478b6031f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jun 17 09:26:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["! nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iri53t0J3Ma0"},"outputs":[],"source":["import os\n","\n","class Config:\n","    AUTHOR = \"wanwan7123\"\n","\n","    NAME = \"USP-Exp040-bert-for-patent\"\n","    MODEL_PATH = \"anferico/bert-for-patents\"\n","    DATASET_PATH = []\n","\n","    COMPETITION = \"us-patent-phrase-to-phrase-matching\"\n","    COLAB_PATH = \"/content/drive/MyDrive/DataAnalysis/competicion/competition_USPPPM\" \n","    DRIVE_PATH = os.path.join(COLAB_PATH, AUTHOR)\n","\n","    api_path = \"/content/drive/MyDrive/kaggle.json\"\n","\n","    seed = 17\n","    num_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    batch_size = 16\n","    n_epochs = 7\n","    max_len = 134\n","    \n","    fc_dropout = 0.1\n","    weight_decay = 0.01\n","    beta = (0.9, 0.98)\n","    lr = 5e-6\n","    num_warmup_steps_rate = 0.01\n","    clip_grad_norm = None\n","    gradient_accumulation_steps = 1\n","\n","    upload_from_colab = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5112,"status":"ok","timestamp":1655457996583,"user":{"displayName":"Tomoya Yanagi","userId":"11157828680567606809"},"user_tz":-540},"id":"Y3qpAE-53Teb","outputId":"aadeb5e0-2f96-41bb-e9d7-2c1b0d03adbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch==1.9.1 in /usr/local/lib/python3.7/dist-packages (1.9.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (4.2.0)\n"]}],"source":["import os\n","import re\n","import gc\n","import sys\n","import json\n","import time\n","import shutil\n","import joblib\n","import random\n","import requests\n","import warnings\n","warnings.filterwarnings('ignore')\n","from ast import literal_eval\n","from tqdm.auto import tqdm\n","from pathlib import Path\n","from glob import glob\n","\n","import numpy as np\n","import pandas as pd\n","import scipy \n","import itertools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import (\n","    StratifiedKFold, \n","    KFold, \n","    GroupKFold,\n","    StratifiedGroupKFold\n",")\n","\n","! pip install torch==1.9.1\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zS5FvS83UY_"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    cfg.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    if cfg.COLAB:\n","        print('This environment is Google Colab')\n","\n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","\n","        # pip install\n","        ! pip install transformers==4.16.2\n","        ! pip install tokenizers==0.11.6\n","        ! pip install transformers[sentencepiece]\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.DRIVE_PATH\n","        cfg.EXP = (cfg.NAME if cfg.NAME is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.COMPETITION -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.COMPETITION+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.DATASET_PATH:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.COMPETITION}'\n","        cfg.EXP = cfg.NAME\n","        cfg.OUTPUT_EXP = cfg.NAME\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQS0vaZd8A8-"},"outputs":[],"source":["# =====================\n","# Utils\n","# =====================\n","# Seed\n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","# KFold\n","def get_kfold(train, n_splits, seed):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train)\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_stratifiedkfold(train, target_col, n_splits, seed):\n","    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    generator = kf.split(train, train[target_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupkfold(train, target_col, group_col, n_splits):\n","    kf = GroupKFold(n_splits=n_splits)\n","    generator = kf.split(train, train[target_col], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series\n","\n","def get_groupstratifiedkfold(train, target_col, group_col, n_splits, seed):\n","    kf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    train['score_map'] = train[target_col].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","    generator = kf.split(train, train['score_map'], train[group_col])\n","    fold_series = []\n","    for fold, (idx_train, idx_valid) in enumerate(generator):\n","        fold_series.append(pd.Series(fold, index=idx_valid))\n","    fold_series = pd.concat(fold_series).sort_index()\n","    return fold_series"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N9c3uiSU3mDy"},"outputs":[],"source":["# =====================\n","# Dataset, Model\n","# =====================\n","\n","def get_cpc_texts():\n","    '''\n","    contextを説明文に変える\n","    '''\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir(os.path.join(cfg.INPUT, 'CPCSchemeXML202105')):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(os.path.join(cfg.INPUT, f'CPCTitleList202202/cpc-section-{cpc}_20220201.txt')) as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        pattern = \"^\"+pattern[:-2]\n","        cpc_result = re.sub(pattern, \"\", result[0])\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            pattern = \"^\"+pattern[:-2]\n","            results[context] = cpc_result + \". \" + re.sub(pattern, \"\", result[0])\n","    return results\n","\n","def processing_features(df):\n","    cpc_texts = get_cpc_texts()\n","    torch.save(cpc_texts, cfg.EXP_FIG+\"cpc_texts.pth\")\n","    df['context_text'] = df['context'].map(cpc_texts)\n","    # 区切りを入れて全部くっつける\n","    df['text'] = df['anchor'] + '[SEP]' + df['target'] + '[SEP]' + df['context_text']\n","    return df\n","\n","# dataset\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].to_numpy()\n","        self.labels = df['score'].to_numpy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        inputs = self.prepare_input(self.cfg, self.texts[index])\n","        label = torch.tensor(self.labels[index], dtype=torch.half)\n","        return inputs, label\n","\n","    @staticmethod\n","    def prepare_input(cfg, text):\n","        inputs = cfg.tokenizer(text, \n","                               add_special_tokens=True,\n","                               max_length=cfg.max_len,\n","                               padding=\"max_length\",\n","                               truncation=True,\n","                               return_offsets_mapping=False)\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","        return inputs\n","\n","def collatte(inputs, labels=None):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    if not labels is None:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        labels =  labels[:,:mask_len]\n","        return inputs, labels, mask_len\n","                \n","    else:\n","        inputs = {\n","            \"input_ids\" : inputs['input_ids'][:,:mask_len],\n","            \"attention_mask\" : inputs['attention_mask'][:,:mask_len],\n","        }\n","        return inputs, mask_len\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.config = AutoConfig.from_pretrained(\n","            cfg.MODEL_PATH,\n","            output_hidden_states=True\n","        )\n","        self.backbone = AutoModel.from_pretrained(\n","            cfg.MODEL_PATH,\n","            config=self.config\n","        )\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, 1)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, inputs):\n","        outputs = self.backbone(**inputs)\n","        last_hidden_state = outputs[0]\n","        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        out = sum_embeddings / sum_mask\n","        out = self.layer_norm1(out)\n","        output = self.fc(out)\n","        \n","        return output.flatten()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-kDMGg-8i-I"},"outputs":[],"source":["def training(cfg, train):\n","    # =====================\n","    # Training\n","    # =====================\n","    set_seed(cfg.seed)\n","    oof_pred = np.zeros(len(train), dtype=np.float32)\n","    for fold in cfg.trn_fold:\n","        # dataset, dataloader\n","        train_df = train.loc[cfg.folds!=fold]\n","        valid_df = train.loc[cfg.folds==fold]\n","        train_idx = list(train_df.index)\n","        valid_idx = list(valid_df.index)\n","\n","        train_dataset = TrainDataset(cfg, train_df)\n","        valid_dataset = TrainDataset(cfg, valid_df)\n","        train_loader = DataLoader(\n","            dataset=train_dataset, \n","            batch_size=cfg.batch_size, \n","            shuffle=True,\n","            pin_memory=True,\n","            drop_last=True\n","        )\n","        valid_loader = DataLoader(\n","            dataset=valid_dataset,\n","            batch_size=cfg.batch_size,\n","            shuffle=False,\n","            pin_memory=True,\n","            drop_last=False\n","        )\n","\n","        # model\n","        model = CustomModel(cfg)\n","        torch.save(model.config, cfg.EXP_MODEL+'config.pth')\n","        model = model.to(cfg.device)\n","\n","        # optimizer, scheduler\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {\n","                'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                'weight_decay': cfg.weight_decay\n","            },\n","            {\n","                'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                'weight_decay': 0.0\n","            }\n","        ]\n","        optimizer = AdamW(\n","            optimizer_grouped_parameters,\n","            lr=cfg.lr,\n","            betas=cfg.beta,\n","            weight_decay=cfg.weight_decay,\n","        )\n","        num_train_optimization_steps = int(\n","            len(train_loader) * cfg.n_epochs // cfg.gradient_accumulation_steps\n","        )\n","        num_warmup_steps = int(num_train_optimization_steps * cfg.num_warmup_steps_rate)\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps,\n","            num_training_steps=num_train_optimization_steps\n","        )\n","\n","        # model-training\n","        criterion = nn.MSELoss()\n","        best_val_score = -1\n","        \n","        for epoch in range(cfg.n_epochs):\n","            # training\n","            print(f\"# ============ start epoch:{epoch} ============== #\")\n","            model.train() \n","            val_losses_batch = []\n","            scaler = GradScaler()\n","            with tqdm(train_loader, total=len(train_loader)) as pbar:\n","                for step, (inputs, labels) in enumerate(pbar):\n","                    for k, v in inputs.items():\n","                        inputs[k] = v.to(cfg.device)\n","                    labels = labels.to(cfg.device)\n","\n","                    optimizer.zero_grad()\n","                    with autocast():\n","                        output = model(inputs)\n","                    loss = criterion(output, labels)\n","                    pbar.set_postfix({\n","                        'loss': loss.item(),\n","                        'lr': scheduler.get_lr()[0]\n","                    })\n","\n","                    if cfg.gradient_accumulation_steps \u003e 1:\n","                        loss = loss / cfg.gradient_accumulation_steps\n","\n","                    scaler.scale(loss).backward()\n","                    if cfg.clip_grad_norm is not None:\n","                        torch.nn.utils.clip_grad_norm_(\n","                            model.parameters(), \n","                            cfg.clip_grad_norm\n","                        )\n","                    if (step+1) % cfg.gradient_accumulation_steps == 0:\n","                        scaler.step(optimizer)\n","                        scaler.update()\n","                        scheduler.step()\n","\n","            # evaluating\n","            val_preds = []\n","            val_losses = []\n","            val_nums = []\n","            model.eval()\n","            with torch.no_grad():\n","                with tqdm(valid_loader, total=len(valid_loader)) as pbar:\n","                    for (inputs, labels) in pbar:\n","                        for k, v in inputs.items():\n","                            inputs[k] = v.to(cfg.device)\n","                        labels = labels.to(cfg.device)\n","                        with autocast():\n","                            output = model(inputs)\n","                        loss = criterion(output, labels.to(torch.float))\n","                        \n","                        output = output.detach().cpu().numpy()\n","                        val_preds.append(output)\n","                        val_losses.append(loss.item() * len(labels))\n","                        val_nums.append(len(labels))\n","                        pbar.set_postfix({\n","                            'val_loss': loss.item()\n","                        })\n","\n","            val_preds = np.concatenate(val_preds)\n","            val_loss = sum(val_losses) / sum(val_nums)\n","            corr_score = np.corrcoef(val_preds, valid_df['score'])[0, 1]\n","\n","            val_log = {\n","                'val_loss': val_loss,\n","                'score': corr_score,\n","            }\n","            display(val_log)\n","\n","            if best_val_score \u003c corr_score:\n","                print(\"save model weight\")\n","                best_val_preds = val_preds\n","                best_val_score = corr_score\n","                torch.save(\n","                    model.state_dict(), \n","                    os.path.join(cfg.EXP_MODEL, f\"fold{fold}.pth\")\n","                )\n","\n","        oof_pred[valid_idx] = best_val_preds.astype(np.float32)\n","        np.save(os.path.join(cfg.EXP_PREDS, f'oof_pred_fold{fold}.npy'), best_val_preds)\n","        del model; gc.collect()\n","\n","    np.save(os.path.join(cfg.EXP_PREDS, 'oof_pred.npy'), oof_pred)\n","\n","    # =====================\n","    # scoring\n","    # =====================\n","    corr_score = np.corrcoef(oof_pred, train['score'])[0, 1]\n","    print('CV:', round(corr_score, 5))\n","    return corr_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":0},"id":"gSrrvDWVpxN_"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.16.2 in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2022.6.2)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.7.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.11.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.64.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (0.0.53)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.16.2) (2.23.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers==4.16.2) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers==4.16.2) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers==4.16.2) (3.8.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==4.16.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==4.16.2) (7.1.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.11.6 in /usr/local/lib/python3.7/dist-packages (0.11.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003e=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.7.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.11.4)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.64.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.7.0)\n","Requirement already satisfied: sentencepiece!=0.1.92,\u003e=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers[sentencepiece]) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers[sentencepiece]) (3.8.0)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers[sentencepiece]) (1.15.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers[sentencepiece]) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers[sentencepiece]) (1.1.0)\n","env: TOKENIZERS_PARALLELISM=true\n","tokenizers.__version__: 0.11.6\n","transformers.__version__: 4.16.2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5df340c34834ffab17d987070d2c21f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/327 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f6b38a9b28146c08787c432acca873f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/322k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"deb3cdea54c14cf3bef05f8ba988cc5c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.29G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8835b5a8e2454194acbf3636d7c7b06d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6e24a8cb0074f35afdae2542685c87a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7740318108362786, 'val_loss': 0.030071474453258237}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fede12e4b1234b28aac1925de98b2df4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"443dd25ef0714fa09521027133f1ac34","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8088658164019205, 'val_loss': 0.028796900176672104}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50937ec74e0e483283cbb46306048124","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1f89d73419641058ce8546c792b1519","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8161450856572453, 'val_loss': 0.023654443888331416}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e597ea95700455bbdb4c43dd3f83da1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4ad6a689db944f4b7a4d3aadd3a2cd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8181318378577523, 'val_loss': 0.022775368686782007}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bd33f2d573e463b820707f316ea5d6d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee5bded8a75546b99e5d00e9ef0cdbad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.818712988055209, 'val_loss': 0.022158348665068193}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24c792ddafd44404bccb9e1f10ba318f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55552463fba647e687850f76f10b14bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8162053588182518, 'val_loss': 0.023307348065154918}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86bb9217760f4d2b85f100abb36f971d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1830 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5aa1f5ddd9e4b58ab5c37a967bb7e64","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/450 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8168058649788132, 'val_loss': 0.02285628541045355}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ce6b3e95fe34a5aa8fd227b1d6da62e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70f8d875e6cc452db3cb45ca42ad7588","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.788218010418177, 'val_loss': 0.02558688120052779}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1aa42c4e9f054ddfab7d728ff403b23f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22ebe22de22948338c01a11aa19c4d0a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8145823168030719, 'val_loss': 0.02441435672636931}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba80c40ab56e43ee94df595f8d877662","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f582dcfb21a14518be6c433ebf47a9d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8210115770059433, 'val_loss': 0.02354930110313255}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d419ec43273477290837dd0be347155","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37d0703af3344200b23a175b350253ef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.82163513491263, 'val_loss': 0.023063518522010162}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09056ce037574fc0ad130075b6fa5bb6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdadbd34ffd04f7990ad7fe4457b0f1a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8183572644517678, 'val_loss': 0.025997600171697253}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51766e16654b4fc0b8317d63acd85b14","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da336553b6a64aa1a8106040b091718d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8228201679772903, 'val_loss': 0.0225960458483237}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec258e058a984bea8b01a351d441212f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1807 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc504291e85d4d1a88fa383260f9e696","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/472 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8227573435289767, 'val_loss': 0.022790672835485765}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"110f91b22bfb45979d212ba706485273","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7167630da898481291eed7d452a30f9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7594623615652566, 'val_loss': 0.031016923429625268}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58f9446f64084966a5184a9ba3938b75","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e856615fb6c54e66b93830a5524fe398","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7906691948076702, 'val_loss': 0.02596424889380708}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7ffaf8753ae4a089f0b0b6532635438","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1ce1a4551294278915eb7fe11486aa5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7972675174879786, 'val_loss': 0.024839028903739166}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98a1c8306c4b4c8a99353990c9f15801","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37154a32c0df40c7914ab9dc21502dab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7995071867129224, 'val_loss': 0.025328555985395386}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68bb5d61187d4148a6946dd6a407dc4d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c05128519024a02bdf1a39b92f4ab4b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7972814989005303, 'val_loss': 0.026090112107971533}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa3455ebd2ae47838e25acc92eda5cad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa4752367c86443db1d2fe8865232e87","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7977090572367141, 'val_loss': 0.025914667044737893}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0ceef7cfbb84a00a717655a58bcf86c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1801 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23a1db6204a84835be2684301be844c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/479 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7977904596464979, 'val_loss': 0.02534059759735181}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27ec4a16dc53438c9aacce94befb4585","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2334bf60c2ab4c80834988df7e5ec6be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8003812424672486, 'val_loss': 0.025753657279830342}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3cab02585d2414caf8d2d327e1967f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4f73dd8b12740419224821a14c02341","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8227257818666641, 'val_loss': 0.022038997029584537}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ae3ad15b7494caaa1d193e8f38320e2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"120b58437f1646f78bc451ad33a9b0cc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8189700376712009, 'val_loss': 0.02992922336891402}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2a0da5a02cc429d9877cc341576be21","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09a2cae7318f42618f61bbf73e068918","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8209606198770218, 'val_loss': 0.023638447557876183}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b940450550034001930a2b0dee56012a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26378451a7d54b75b231f952d3ca107e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8209382427836296, 'val_loss': 0.023377274024052094}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89688f6c2d8640fe8e2d72ff2df0ad6a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea4838092b924304b3c543f64b271f2d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8185563072458044, 'val_loss': 0.023889483310804333}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da1e49bdf7af44b5b70837206c69fdb7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1840 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d665e1b01da74d71b25c14f44c404c93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/439 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8193719010107605, 'val_loss': 0.02394869351758757}"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["# ============ start epoch:0 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b8a15f133914e28872612e85029a5d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9ace94ff1ae40c7a04143ea3eb70a3a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.7846918486797663, 'val_loss': 0.02900673585525251}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:1 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d2b4ebebe424b1f96f0f2e64c03fe45","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b85dcb452cf24b2bb64cbcc1dfb5aeb2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8080939546905723, 'val_loss': 0.03065766578740482}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:2 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f88ab9a9633149f593a49536c43a8096","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e8cfed5f3e0427884811dceb8a6acb1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8097373318123192, 'val_loss': 0.024764497696462544}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:3 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"836200acc6e04f69a7b89eecdd369c8d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4aa4dfce807447219b37579c1d2f720f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8103546617604941, 'val_loss': 0.02445997728581325}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:4 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"106dd64fe69c42c8a7097fd525742046","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcfea1825a7d4eab860542034137f623","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.81064125951965, 'val_loss': 0.025466926882202066}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:5 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"864a85ac3c85426ba610fe3c1f9bb67d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"924e099209524a768f6e1af63fabc2df","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8110937646771835, 'val_loss': 0.023971045007954273}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["save model weight\n","# ============ start epoch:6 ============== #\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f892522313a84426aaddfbd058a6f84a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1838 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f6999ee86464b489995acc301694837","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/442 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'score': 0.8102011479922657, 'val_loss': 0.02440971353428127}"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CV: 0.81393\n","Starting upload for file model.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.42G/6.42G [02:18\u003c00:00, 49.7MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: model.tar (6GB)\n","Starting upload for file fig.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10.0k/10.0k [00:00\u003c00:00, 51.3kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: fig.tar (10KB)\n","Starting upload for file preds.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500k/500k [00:00\u003c00:00, 2.35MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: preds.tar (500KB)\n","Starting upload for file figcpc_texts.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13.9k/13.9k [00:00\u003c00:00, 76.4kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: figcpc_texts.pth (14KB)\n","Starting upload for file tokenizer.tar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1.24M/1.24M [00:00\u003c00:00, 6.35MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: tokenizer.tar (1MB)\n","Starting upload for file modelconfig.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2.17k/2.17k [00:00\u003c00:00, 11.5kB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Upload successful: modelconfig.pth (2KB)\n"]}],"source":["# =====================\n","# Main\n","# =====================\n","\n","# setup\n","cfg = setup(Config)\n","\n","import transformers\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","import tokenizers\n","import sentencepiece\n","%env TOKENIZERS_PARALLELISM=true\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","\n","# main\n","train = pd.read_csv(os.path.join(cfg.INPUT, 'train.csv'))\n","test = pd.read_csv(os.path.join(cfg.INPUT, 'test.csv'))\n","sub = pd.read_csv(os.path.join(cfg.INPUT, 'sample_submission.csv'))\n","\n","train = processing_features(train)\n","test = processing_features(test)\n","\n","cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.MODEL_PATH)\n","cfg.tokenizer.save_pretrained(os.path.join(cfg.OUTPUT_EXP, 'tokenizer'))\n","cfg.folds = get_groupstratifiedkfold(train, 'score', 'anchor', cfg.num_fold, cfg.seed)\n","cfg.folds.to_csv(os.path.join(cfg.EXP_PREDS, 'folds.csv'))\n","score = training(cfg, train)\n","\n","if cfg.upload_from_colab and cfg.COLAB:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYumfMTa81vp"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOyUDwdY3S80PzEX4IpzN0I","background_execution":"on","machine_shape":"hm","mount_file_id":"1UYXX3Wlqu3EOee9sQo_J0qP_XipGi2GY","name":"exp040.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"079b9cf2787d45029f1e134830ea6498":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1001598ab9104fa5b2e9837452c64bb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62cf5f36d1244d41ba0039c0c4a9a382","max":329241,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb8342909b374208869cbfdb5a704d73","value":329241}},"1ae6e09597dd480696f96ba9d6027e19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c4962c683724185bbe627d5249e2674":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26d6710c862246a7af6bbaadeab20dc8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2950d77543e64b6fb9470094e797f297":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_079b9cf2787d45029f1e134830ea6498","max":327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ad693b49a1741bcb975956a6f962930","value":327}},"2cd00563f3eb44fb9a28c2ff2c41b4e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35df95a765174265a14228c7d572f3b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3950d2e76071450784e73db77c98df44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83a1f5c47eb245acaeffcb19064d6b1b","placeholder":"​","style":"IPY_MODEL_538e1a02b64746bab6b1af3f9dd47047","value":"Downloading: 100%"}},"486397bb6672441aac8a801f92fd911a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d9f46e4d7b6403cb307b838fb238c56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_486397bb6672441aac8a801f92fd911a","placeholder":"​","style":"IPY_MODEL_1ae6e09597dd480696f96ba9d6027e19","value":" 327/327 [00:00\u0026lt;00:00, 10.2kB/s]"}},"4f4a565a452d495191794cab5f8c3e21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fc1fcc9f410480ba8dcf40d869408de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538e1a02b64746bab6b1af3f9dd47047":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55f485a0f8be4b13b4781c42e1871815":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f6b38a9b28146c08787c432acca873f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ceac64a6332a4b728dd68e7ed4ba3c7c","IPY_MODEL_1001598ab9104fa5b2e9837452c64bb0","IPY_MODEL_87c3b1161d154ca38aed3c5fe85b95f0"],"layout":"IPY_MODEL_1c4962c683724185bbe627d5249e2674"}},"62cf5f36d1244d41ba0039c0c4a9a382":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad693b49a1741bcb975956a6f962930":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6faa7a941f094722951e59bf17ad14a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26d6710c862246a7af6bbaadeab20dc8","placeholder":"​","style":"IPY_MODEL_35df95a765174265a14228c7d572f3b5","value":"Downloading:  93%"}},"79347ae9c9a74a4fb2d16cd7bffe27e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eea079ae3dd4cf8bbe16fc3b450e4b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eed998d02374a53ab2142ff6fa36780","max":1383349812,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b01309cc198442b5b01c6a8288662485","value":1292500992}},"83a1f5c47eb245acaeffcb19064d6b1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87c3b1161d154ca38aed3c5fe85b95f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc1fcc9f410480ba8dcf40d869408de","placeholder":"​","style":"IPY_MODEL_c3d7d0433bbe46ed8e7ae480c3f2bf5e","value":" 322k/322k [00:00\u0026lt;00:00, 3.56MB/s]"}},"8eed998d02374a53ab2142ff6fa36780":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ba73aea225841c19c00543f0702abbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b01309cc198442b5b01c6a8288662485":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5df340c34834ffab17d987070d2c21f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3950d2e76071450784e73db77c98df44","IPY_MODEL_2950d77543e64b6fb9470094e797f297","IPY_MODEL_4d9f46e4d7b6403cb307b838fb238c56"],"layout":"IPY_MODEL_2cd00563f3eb44fb9a28c2ff2c41b4e9"}},"b618c00cbf0a4b58bb2d35650efd51c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d7d0433bbe46ed8e7ae480c3f2bf5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c97e42580b47414aa3b4094a96c9a9bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79347ae9c9a74a4fb2d16cd7bffe27e8","placeholder":"​","style":"IPY_MODEL_9ba73aea225841c19c00543f0702abbd","value":" 1.20G/1.29G [00:28\u0026lt;00:01, 48.6MB/s]"}},"ceac64a6332a4b728dd68e7ed4ba3c7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4a565a452d495191794cab5f8c3e21","placeholder":"​","style":"IPY_MODEL_55f485a0f8be4b13b4781c42e1871815","value":"Downloading: 100%"}},"deb3cdea54c14cf3bef05f8ba988cc5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6faa7a941f094722951e59bf17ad14a4","IPY_MODEL_7eea079ae3dd4cf8bbe16fc3b450e4b4","IPY_MODEL_c97e42580b47414aa3b4094a96c9a9bb"],"layout":"IPY_MODEL_b618c00cbf0a4b58bb2d35650efd51c9"}},"eb8342909b374208869cbfdb5a704d73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}